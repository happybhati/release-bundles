---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: publish-index-image
  labels:
    app.kubernetes.io/version: "3.3.0"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
      Publish a built FBC index image using skopeo
  params:
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: sourceIndex
      type: string
      description: Pullspec to pull the image from
    - name: targetIndex
      type: string
      description: Pullspec to push the image to
    - name: retries
      type: string
      default: "0"
      description: Number of skopeo retries
    - name: requestTimeout
      type: string
      default: "360"
      description: Max seconds waiting for the status update
    - name: buildTimestamp
      type: string
      description: Build timestamp for the publishing image
    - name: pipelineRunUid
      type: string
      description: The UID of the current pipelineRun. Used as a label value when creating internal requests
  workspaces:
    - name: data
      description: Workspace to store the params and responses for the internalRequest
  results:
    - name: requestMessage
      type: string
  steps:
    - name: publish-index-image
      image: >-
        quay.io/konflux-ci/release-service-utils:e633d51cd41d73e4b3310face21bb980af7a662f
      script: |
        #!/usr/bin/env bash
        set -euo pipefail

        DATA_FILE="$(workspaces.data.path)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi

        request="publish-index-image-pipeline"
        credentials=$(jq -r '.fbc.publishingCredentials' "$DATA_FILE")
        pipelinerun_label="internal-services.appstudio.openshift.io/pipelinerun-uid"

        publishingImages=("$(params.targetIndex)")
        # only publish the extra timestamp-based tag if the targetIndex does not have it already
        if [[ ! "$(params.targetIndex)" =~ .*$(params.buildTimestamp)$ ]]; then
          publishingImages+=("$(params.targetIndex)-$(params.buildTimestamp)")
        fi

        # Prepare authentication for skopeo
        AUTH_FILE="$(workspaces.data.path)/authfile.json"
        echo "${credentials}" > "${AUTH_FILE}"

        for target_image in "${publishingImages[@]}"; do
            echo "=== Processing Image ==="
            echo "Source: $(params.sourceIndex)"
            echo "Target: ${target_image}"

            # Check if the target image exists
            set +e
            existing_digest=$(skopeo inspect --authfile "${AUTH_FILE}" "docker://${target_image}" --format '{{.Digest}}' 2>/dev/null)
            inspect_exit_code=$?
            set -e

            # Get the source image digest
            source_digest=$(skopeo inspect --authfile "${AUTH_FILE}" "docker://$(params.sourceIndex)" --format '{{.Digest}}')

            if [ $inspect_exit_code -eq 0 ]; then
                if [ "$existing_digest" == "$source_digest" ]; then
                    echo "Image ${target_image} already exists with the same digest. Skipping publishing." | tee "$(results.requestMessage.path)"
                    continue
                else
                    echo "Image ${target_image} exists but has a different digest. Skipping to avoid overwriting." | tee "$(results.requestMessage.path)"
                    continue
                fi
            fi

            echo "Publishing image to ${target_image}..."

            internal-request -r "${request}" \
                -p sourceIndex="$(params.sourceIndex)" \
                -p targetIndex="${target_image}" \
                -p publishingCredentials="${credentials}" \
                -p retries="$(params.retries)" \
                -t "$(params.requestTimeout)" \
                -l ${pipelinerun_label}="$(params.pipelineRunUid)"

            echo "Published image ${target_image} successfully." | tee "$(results.requestMessage.path)"
            echo ""
        done

        # Clean up the authentication file
        rm -f "${AUTH_FILE}"
